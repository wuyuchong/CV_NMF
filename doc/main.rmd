---
documentclass: ctexart
output:
  rticles::ctex:
    fig_caption: yes
    number_sections: yes
    template: template.tex
    highlight: tango
classoption: "hyperref,"
geometry: margin=1in
csl: chinese-gb7714-2005-numeric.csl
bibliography: reference.bib
header-includes:
   - \usepackage{graphicx}
   - \usepackage{float}
   - \usepackage{indentfirst}
   - \setlength{\parindent}{4em}
logo: "cufe.jpg"
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.pos = 'H', echo = FALSE, warning = FALSE, message = FALSE, comment = NA)
library(rmarkdown)
library(knitr)
library(tidyverse)
library(scales)
# base_family = 'STXihei'
```

# 报告概述{-}

使用服饰图像分类数据集，我们探究降维对于图像识别的有效性。

未降维时变量数量过多，我们发现只有当模型参数数量充足时，才能解决拟合不足问题。且深度学习和随机森林尽管总体准确率达到 80% 以上，但品类间预测效果差距较大，部分品类准确率较低。

在使用 NMF 和 PCA 进行降维之后，降维对特征的提取效果较好， 可较大程度地加快模型的训练速度，增强模型的收敛效果，各类准确率达到 90% 以上。

对错判结果分析后我们发现，图像识别主要依靠图像中的形状特征，因此有些在人类看来完全不同类的物品，模型的错判率反而比同类物品高。

# 数据集介绍

```{r, out.width='70%', fig.align='center', fig.cap = '数据集概览'}
knitr::include_graphics("../figure/fashion-mnist-sprite.png")
```

我们使用 `Fashion-MNIST` 数据集^[https://github.com/zalandoresearch/fashion-mnist] ，它共有 6 万条训练样本和 1 万条测试样本，图片像素为 28 X 28，颜色为灰度。这些图片为服饰的照片，共分为 10 类。@xiao2017online

```{r}
classNames = c("T恤/上衣" , "裤子" , "套头衫" , "连衣裙" , "外套" , "凉鞋" , "衬衫" , "运动鞋" , "包" , "短靴")
labels = data.frame(标签 = 0:9, 名称 = classNames)
kable(t(labels), caption = '标签与分类名称')
```

由于我们的训练样本和测试样本中，每个类别的样本数量相同，是一个平衡的数据集，因此我们选用准确率作为我们的模型评价指标。

使用 R 画出一个示例图像如下：

```{r, out.width='30%', fig.align='center', fig.cap = '图像示例'}
knitr::include_graphics("../figure/图像示例.pdf")
```

在数据预处理中，我们使用标准化对灰度值进行处理，以提高模型收敛的速度和效果。

$$x_{i}^{\prime}=\frac{x_{i}-(\max (x)-\min (x)) / 2}{(\max (x)-\min (x)) / 2}$$

# 未降维

在未降维的情况下，我们建立模型作为基准。

## NNET

我们使用 NNET @nnet 建立一个较为简单的神经网络模型，以观察模型参数个数与预测准确率的关系。^[NNET用时约1小时（阿里云服务器 Xeon 8核 CPU 32G 内存）]

```{r}
table = read.csv("../output/corrateNNET.csv")
table = mutate(table, corrate_rate = percent(corrate_rate, 2))
names(table) = c("网络大小", "准确率")
kable(t(table), caption = '神经网络模型的准确率')
```

随着网络大小的增加，预测准确率逐渐上升。这是因为由于未降维时变量数量过多，神经网络的大小不得不设置得非常大，模型才能被充分训练。

## 深度学习

我们使用 python 在 `TensorFlow` 框架下搭建一个多层神经网络。 @tensorflow 我们在中间层使用 Relu 作为激活函数，使用 Adam 作为优化器。^[未降维的 python 深度学习训练用时约 4 分钟（阿里云服务器 Xeon 8核 CPU 32G 内存）]

由于我们进行分类任务，需要约束输出的十类的预测概率值之和为 1，因此我们在输出层使用 Softmax 函数：

$$\sigma(\mathbf{z})_{i}=\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}} \quad \text { for } i=1, \ldots, K \text { and } \mathbf{z}=\left(z_{1}, \ldots, z_{K}\right) \in \mathbb{R}^{K}$$

```{r}
神经网络层 = c('输入层', 'drop out (20%)', '中间层1', 'drop out (50%)', '中间层2', 'drop out (50%)', '输出层')
神经元个数 = c(784, 0, 128, 0, 128, 0, 10)
table = data.frame(神经网络层, 神经元个数)
kable(table, caption = '搭建的神经网络结构')
```

```{r, out.width='99%', fig.align='center', fig.cap = '深度学习预测结果'}
knitr::include_graphics("../figure/深度学习预测结果.pdf")
```

在未降维时，使用深度学习进行识别的正确率约为 85%。对于一些较为相似的品类，模型可能会发生错判，如上图中的衬衫，虽然最终预测是正确的，模型认为有 14% 的概率为 T恤。

## 随机森林模型

搭建一个树的数目取 10 的随机森林模型 @randomForest ^[未降维的随机森林模型训练用时约 40 分钟（阿里云服务器 Xeon 8核 CPU 32G 内存）]

```{r, out.width='70%', fig.align='center', fig.cap = '随机森林不同类别预测正确率'}
knitr::include_graphics("../figure/随机森林不同类别预测正确率.pdf")
```

对于此未降维的模型，部分品类的预测准确率较高，然而衬衫的准确率很低，仅有约 50%。

# 降维

由于未降维时模型的变量过多，收敛速度慢且收敛效果不佳，需要更多参数、更长时间的训练才能达到充分拟合。所以我们尝试使用降维方法对图像进行特征提取，之后再使用随机森林模型进行训练及预测。

## 降维后特征

我们使用 NMF @liumiao 将数据集降维至 12 维，降维后的新变量反映了原数据集中各个类别的特征。^[降维用时约 20 分钟（阿里云服务器 Xeon 8核 CPU 32G 内存）]

```{r, out.width='70%', fig.align='center', fig.cap = '降维后的新变量'}
knitr::include_graphics("../figure/降维后的新变量图.pdf")
```

```{r}
table = read.csv("../output/10种不同类别在前六个新变量中的权重.csv")
kable(table, caption = '不同类别在前六个新变量中的权重')
```

## PCA 和 NMF 降维效果对比

我们分别使用 PCA 和 NMF 降低不同的维度，应用于随机森林模型，观察预测效果。^[降维后模型训练速度快于未降维，但由于训练不同降维方法、不同降维维度，总用时约 4 小时（阿里云服务器 Xeon 8核 CPU 32G 内存）]

```{r, out.width='99%', fig.align='center', fig.cap = 'PCA及NMF在不同维数预测的正确率线图'}
knitr::include_graphics("../figure/PCA及NMF在不同维数预测的正确率线图.pdf")
```

可以看出，由于我们的训练样本达到 6 万条，PCA 和 NMF 在降至 1 维时，就已经可以提供超过 90% 的准确率。

随着维度的增加，PCA 降维方法的准确率有所升高，不过提升幅度不大。而对于 NMF 方法，维度增加准确率波动较为明显，甚至会有所下降，这可能与维度增加后模型拟合不足、收敛速度变慢有关。

\newpage

```{r, out.width='85%', fig.align='center', fig.cap = 'NMF不同类别不同降维度的预测正确率'}
knitr::include_graphics("../figure/NMF不同类别不同降维度的预测正确率.pdf")
```

```{r, out.width='85%', fig.align='center', fig.cap = 'PCA不同类别不同降维度的预测正确率'}
knitr::include_graphics("../figure/PCA不同类别不同降维度的预测正确率.pdf")
```

对 PCA 降维方法，不同类别的准确率差距非常小。对 NMF 降维方法，裤子的错判率最高，包的准确率最高。

# 错判结果分析

```{r, out.width='90%', fig.align='center', fig.cap = '6维NMF降维随机森林错判图'}
knitr::include_graphics("../figure/6维NMF降维随机森林错判图.pdf")
```

对外套图像，117 次模型错判为衬衫，但只有 76 次错判为裤子，符合预期。

对衬衫图像，124 次模型错判为套头衫，但只有 88 次错判为 T恤，这与我们的直觉相符合，套头衫由于与衬衫都为长袖，错判率较高。

对短靴图像，尽管直觉上我们猜测可能易与运动鞋混淆，然而事实上错判成为运动鞋的次数并不多，原因是尽管短靴和运动鞋都属于鞋类，然而它们在脚跟处的形状却有着很大的差别，故预测时混淆次数较少。同样的我们发现，尽管衬衫和包在人类看来是两类完全不同的东西，然而在图像识别时，两者的整体轮廓较为相似，故错判率较高。

# 总结

1. 在不降维的情况下，我们发现 由于未降维时变量数量过多，神经网络的大小不得不设置得非常大，模型才能被充分训练。且深度学习和随机森林的结果表明，尽管某些品类预测准确率达到 80% 以上，但仍有品类预测效果较差。
1. 在使用 NMF 和 PCA 进行降维之后，降维对特征的提取效果较好， 可较大程度地加快模型的训练速度，增强模型的收敛效果。
1. 随着维度的增加，PCA 降维方法的准确率有所升高，不过提升幅度不大。而对于 NMF 方法，维度增加准确率波动较为明显，甚至会有所下降，这可能与维度增加后模型拟合不足、收敛速度变慢有关。
1. 对错判结果分析后我们发现，大部分情况下同类物品容易产生混淆，与我们的预期相一致。但有些在人类看来完全不同类的物品，模型的错判率反而比同类物品高，这是由于图像识别主要依靠图像中的形状特征，如衬衫和包尽管类别不同，但其图像外形轮廓较为相似。

# 参考文献

<div id="refs"></div>

\newpage

# 附录

## 代码目录结构

```{bash, eval=F, echo=T, code=xfun::read_utf8('../structure.txt')}
```

## 主程序

### R

```{r, eval=F, echo=T, code=xfun::read_utf8('../code/main.R')}
```

### python: 深度学习

```{python, eval=F, echo=T, code=xfun::read_utf8('../code/deep_learning.py')}
```

## 函数封装

### 数据集加载

```{r, eval=F, echo=T, code=xfun::read_utf8('../code/src/load.R')}
```

### 模型运行

```{r, eval=F, echo=T, code=xfun::read_utf8('../code/src/model.R')}
```

### 图像输出

```{r, eval=F, echo=T, code=xfun::read_utf8('../code/src/plot.R')}
```

### 表格输出

```{r, eval=F, echo=T, code=xfun::read_utf8('../code/src/table.R')}
```
